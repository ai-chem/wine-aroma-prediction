{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dae67d26-921a-4a56-bb9e-a0b0131c939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from contextlib import nullcontext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9930094b-634b-4d0e-93a9-89d039f9893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, depth=2, n_classes=10, p=0.2, widths=(64,128,256,512,512)):\n",
    "        super().__init__()\n",
    "        self.depth = depth\n",
    "        layers, in_ch = [], 1\n",
    "        for i in range(depth):\n",
    "            out_ch = widths[i]\n",
    "            layers += [\n",
    "                nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.LeakyReLU(inplace=True),\n",
    "                nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            ]\n",
    "            in_ch = out_ch\n",
    "        self.features = nn.Sequential(*layers, nn.AdaptiveAvgPool2d(1))\n",
    "        self.fc1 = nn.Linear(in_ch, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, n_classes)\n",
    "        self.dropout = nn.Dropout(p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.leaky_relu(self.fc1(x)); x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        return self.fc3(x)  # logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4a061dd-e8c5-4863-bef4-f536cf18b45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_chw1(x: np.ndarray) -> np.ndarray:\n",
    "    if x.ndim == 2:\n",
    "        x = x[None, ...]\n",
    "    elif not (x.ndim == 3 and x.shape[0] == 1):\n",
    "        raise ValueError(f\"Expected [H,W] or [1,H,W], got {x.shape}\")\n",
    "    x = x.astype(np.float32)\n",
    "    m, s = x.mean(), x.std()\n",
    "    if s == 0: s = 1.0\n",
    "    return (x - m) / (s + 1e-6)\n",
    "\n",
    "def _find_best_ckpt(weights_dir: Path) -> Path:\n",
    "    cands = list(weights_dir.rglob(\"*.pt\"))\n",
    "    if not cands:\n",
    "        raise FileNotFoundError(f\"No .pt files under {weights_dir}\")\n",
    "    have_any_metrics = False\n",
    "    scored = []\n",
    "    for p in cands:\n",
    "        try:\n",
    "            ckpt = torch.load(p, map_location=\"cpu\")\n",
    "            m = ckpt.get(\"metrics\", {}) or {}\n",
    "            vl = float(m.get(\"val_loss\", math.inf))\n",
    "            va = float(m.get(\"val_acc\", -math.inf))\n",
    "            if math.isfinite(vl) or math.isfinite(va):\n",
    "                have_any_metrics = True\n",
    "        except Exception:\n",
    "            vl, va = math.inf, -math.inf\n",
    "        mt = p.stat().st_mtime\n",
    "        scored.append((p, vl, va, mt))\n",
    "    if have_any_metrics:\n",
    "        scored.sort(key=lambda t: (t[1], -t[2], -t[3]))\n",
    "        return scored[0][0]\n",
    "    else:\n",
    "        return max(cands, key=lambda p: p.stat().st_mtime)\n",
    "\n",
    "@torch.no_grad()\n",
    "def _predict_array(model: nn.Module, device: str, arr: np.ndarray, threshold: float):\n",
    "    x = torch.from_numpy(_to_chw1(arr))[None].to(device) \n",
    "    use_amp = (device == \"cuda\")\n",
    "    ctx = torch.amp.autocast(device_type=\"cuda\", enabled=use_amp) if use_amp else nullcontext()\n",
    "    with ctx:\n",
    "        logits = model(x)   \n",
    "        probs = torch.sigmoid(logits).cpu().numpy()[0]\n",
    "    preds = (probs >= threshold).astype(int)\n",
    "    return probs, preds\n",
    "\n",
    "def _load_model_and_meta(ckpt_path: Path, device: str, depth_arg: int = None, n_classes_arg: int = None):\n",
    "    obj = torch.load(ckpt_path, map_location=device)\n",
    "    if \"model_state_dict\" in obj:\n",
    "        state_dict = obj[\"model_state_dict\"]\n",
    "        arch = obj.get(\"arch\", {}) or {}\n",
    "        depth = int(arch.get(\"depth\", depth_arg if depth_arg is not None else 2))\n",
    "        n_classes = int(arch.get(\"n_classes\", n_classes_arg if n_classes_arg is not None else 10))\n",
    "        label_names = obj.get(\"label_names\", None)\n",
    "        threshold = float(obj.get(\"sigmoid_threshold\", 0.5))\n",
    "    else:\n",
    "        if depth_arg is None or n_classes_arg is None:\n",
    "            raise ValueError(\"State dict without arch. Please pass --depth and --n_classes.\")\n",
    "        state_dict = obj\n",
    "        depth, n_classes = depth_arg, n_classes_arg\n",
    "        label_names, threshold = None, 0.5\n",
    "\n",
    "    model = ConvNet(depth=depth, n_classes=n_classes).to(device).eval()\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model, depth, n_classes, label_names, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "955ef9d1-ff03-4b84-8b18-09aa5b906c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--ckpt CKPT] [--weights_dir WEIGHTS_DIR]\n",
      "                             (--input_npy INPUT_NPY | --input_csv INPUT_CSV) [--output_csv OUTPUT_CSV]\n",
      "                             [--threshold THRESHOLD] [--device {auto,cpu,cuda}] [--depth DEPTH]\n",
      "                             [--n_classes N_CLASSES]\n",
      "ipykernel_launcher.py: error: one of the arguments --input_npy --input_csv is required\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    ap = argparse.ArgumentParser(description=\"Multilabel ConvNet inference with auto-picked checkpoint.\")\n",
    "    ap.add_argument(\"--ckpt\", type=str, default=None, help=\"Path to .pt. If omitted: use ./checkpoints/best.pt or auto-pick from ./checkpoints/**\")\n",
    "    ap.add_argument(\"--weights_dir\", type=str, default=\"checkpoints\", help=\"Where to search for weights if --ckpt not provided\")\n",
    "    g = ap.add_mutually_exclusive_group(required=True)\n",
    "    g.add_argument(\"--input_npy\", type=str, help=\"Path to a single .npy file\")\n",
    "    g.add_argument(\"--input_csv\", type=str, help=\"CSV with column 'path' pointing to .npy files\")\n",
    "    ap.add_argument(\"--output_csv\", type=str, default=\"predictions.csv\", help=\"Output CSV path\")\n",
    "    ap.add_argument(\"--threshold\", type=float, default=None, help=\"Override sigmoid threshold (default: from checkpoint or 0.5)\")\n",
    "    ap.add_argument(\"--device\", type=str, choices=[\"auto\",\"cpu\",\"cuda\"], default=\"auto\")\n",
    "    # на случай state_dict-only:\n",
    "    ap.add_argument(\"--depth\", type=int, default=None, help=\"Required if the checkpoint stores state_dict only\")\n",
    "    ap.add_argument(\"--n_classes\", type=int, default=None, help=\"Required if the checkpoint stores state_dict only\")\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    device = \"cuda\" if (args.device == \"auto\" and torch.cuda.is_available()) else (args.device if args.device != \"auto\" else \"cpu\")\n",
    "\n",
    "    if args.ckpt:\n",
    "        ckpt_path = Path(args.ckpt)\n",
    "    else:\n",
    "        best_path = Path(args.weights_dir) / \"best.pt\"\n",
    "        ckpt_path = best_path if best_path.exists() else _find_best_ckpt(Path(args.weights_dir))\n",
    "\n",
    "    model, depth, n_classes, label_names, thr_ckpt = _load_model_and_meta(\n",
    "        ckpt_path, device, depth_arg=args.depth, n_classes_arg=args.n_classes\n",
    "    )\n",
    "    threshold = float(thr_ckpt if args.threshold is None else args.threshold)\n",
    "\n",
    "    if args.input_npy:\n",
    "        arr = np.load(args.input_npy)\n",
    "        probs, preds = _predict_array(model, device, arr, threshold)\n",
    "        cols = label_names if label_names else [f\"class_{i}\" for i in range(n_classes)]\n",
    "        df = pd.DataFrame([probs], columns=cols)\n",
    "        for i, c in enumerate(cols):\n",
    "            df[f\"pred_{c}\"] = int(preds[i])\n",
    "        df.insert(0, \"path\", args.input_npy)\n",
    "        Path(args.output_csv).parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.to_csv(args.output_csv, index=False)\n",
    "        print(f\"[OK] ckpt={ckpt_path}  saved={args.output_csv}\")\n",
    "        return\n",
    "\n",
    "    df_in = pd.read_csv(args.input_csv)\n",
    "    if \"path\" not in df_in.columns:\n",
    "        raise ValueError(\"input_csv must contain column 'path'\")\n",
    "    rows = []\n",
    "    for p in df_in[\"path\"].tolist():\n",
    "        arr = np.load(p)\n",
    "        probs, preds = _predict_array(model, device, arr, threshold)\n",
    "        rows.append((p, probs, preds))\n",
    "\n",
    "    cols = label_names if label_names else [f\"class_{i}\" for i in range(n_classes)]\n",
    "    proba_mat = np.vstack([r[1] for r in rows])     \n",
    "    pred_mat  = np.vstack([r[2] for r in rows]).astype(int)\n",
    "\n",
    "    df_out = pd.DataFrame(proba_mat, columns=cols)\n",
    "    for i, c in enumerate(cols):\n",
    "        df_out[f\"pred_{c}\"] = pred_mat[:, i]\n",
    "    df_out.insert(0, \"path\", [r[0] for r in rows])\n",
    "\n",
    "    Path(args.output_csv).parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_out.to_csv(args.output_csv, index=False)\n",
    "    print(f\"[OK] ckpt={ckpt_path}  saved={args.output_csv}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593b4392-c06d-4ac5-ab83-0e2a6fc460f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
