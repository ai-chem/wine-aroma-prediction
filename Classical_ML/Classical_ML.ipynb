{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application of classical machine learning and MLP methods to predict the flavor of wine by its chemical composition\n",
    "In this section, classical machine learning was applied to predict the flavor of wine from its chemical composition. Several algorithms were used, including decision trees, boosting methods, and MLP, as these approaches are most effective on tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data loading and processing\n",
    "In order to use the obtained chemical composition matrices for classification problems using classical ML methods, it is necessary to \"flatten\" the matrix into a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(449, 44, 100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading matrices and target lists\n",
    "X_array = np.load('X_array.npy')\n",
    "Y_array = np.load('Y_array.npy')\n",
    "X_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Flowers - RandomForest | Train Acc: 1.0000, Train F1: 1.0000 | CV Acc: 0.7495 ± 0.0556, CV F1: 0.7370 ± 0.0650 | Test Acc: 0.6333, Test F1: 0.6347\n"
     ]
    }, 
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peach\\anaconda3\\envs\\practicum\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:31:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Peach\\anaconda3\\envs\\practicum\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:31:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Peach\\anaconda3\\envs\\practicum\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:31:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Peach\\anaconda3\\envs\\practicum\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:32:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Peach\\anaconda3\\envs\\practicum\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:32:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Peach\\anaconda3\\envs\\practicum\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:32:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Peach\\anaconda3\\envs\\practicum\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:32:15] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Peach\\anaconda3\\envs\\practicum\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:32:19] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Peach\\anaconda3\\envs\\practicum\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:32:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Peach\\anaconda3\\envs\\practicum\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:32:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Peach\\anaconda3\\envs\\practicum\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:32:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Flowers - XGBoost | Train Acc: 1.0000, Train F1: 1.0000 | CV Acc: 0.7078 ± 0.0935, CV F1: 0.7048 ± 0.0918 | Test Acc: 0.6556, Test F1: 0.6542\n",
      "Target Flowers - CatBoost | Train Acc: 0.9387, Train F1: 0.9373 | CV Acc: 0.7579 ± 0.0602, CV F1: 0.7463 ± 0.0689 | Test Acc: 0.6556, Test F1: 0.6542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peach\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Peach\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Peach\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Peach\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Peach\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Peach\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Peach\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Peach\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Peach\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Peach\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Flowers - MLP | Train Acc: 0.7604, Train F1: 0.7352 | CV Acc: 0.7106 ± 0.0721, CV F1: 0.6813 ± 0.0896 | Test Acc: 0.6778, Test F1: 0.6510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peach\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Reshaping X_array\n",
    "X_flattened = X_array.reshape(449, 44 * 100)\n",
    "# Number of target parameters\n",
    "num_targets = Y_array.shape[1]\n",
    "target_names = ['Herbs and spices', 'Tobacco/Smoke', 'Wood', 'Berries', 'Citrus',\n",
    "                'Fruits', 'Nuts', 'Coffee', 'Chocolate/Cacao', 'Flowers']\n",
    "\n",
    "# Creating lists to store results\n",
    "results = {\n",
    "    'Target': [],\n",
    "    'Model': [],\n",
    "    'Train Accuracy': [],\n",
    "    'Train F1-Score': [],\n",
    "    'CV Accuracy': [],\n",
    "    'CV Accuracy Std': [],  \n",
    "    'CV F1-Score': [],\n",
    "    'CV F1-Score Std': [],  \n",
    "    'Test Accuracy': [],\n",
    "    'Test F1-Score': []\n",
    "}\n",
    "\n",
    "# Function for cross-validation and model evaluation\n",
    "def cross_validate_and_evaluate(model_name, model, X_train, y_train, X_test, y_test):\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Train set metrics\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "    \n",
    "    # Cross-validation metrics\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    accuracy_scorer = make_scorer(accuracy_score)\n",
    "    f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "    \n",
    "    cv_accuracies = cross_val_score(model, X_train, y_train, cv=kf, scoring=accuracy_scorer)\n",
    "    cv_f1_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring=f1_scorer)\n",
    "    \n",
    "    cv_acc_mean = cv_accuracies.mean()\n",
    "    cv_acc_std  = cv_accuracies.std(ddof=1)  # sample std\n",
    "    cv_f1_mean  = cv_f1_scores.mean()\n",
    "    cv_f1_std   = cv_f1_scores.std(ddof=1)\n",
    "\n",
    "    # Test (один сплит → std не существует на уровне одной задачи)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "    return (train_accuracy, train_f1,\n",
    "            cv_acc_mean, cv_acc_std, cv_f1_mean, cv_f1_std,\n",
    "            test_accuracy, test_f1)\n",
    "\n",
    "# Main loop for training and evaluating models\n",
    "for i in range(num_targets):\n",
    "    # Select the i-th target parameter\n",
    "    y = Y_array[:, i]\n",
    "\n",
    "    # Split into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_flattened, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Models for training\n",
    "    models = {\n",
    "        'RandomForest': RandomForestClassifier(random_state=42),\n",
    "        'XGBoost': XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss'),\n",
    "        'CatBoost': CatBoostClassifier(random_state=42, silent=True),\n",
    "        'MLP': MLPClassifier(random_state=42)\n",
    "    }\n",
    "    \n",
    "    # Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "        (train_acc, train_f1,\n",
    "         cv_acc_mean, cv_acc_std, cv_f1_mean, cv_f1_std,\n",
    "         test_acc, test_f1) = cross_validate_and_evaluate(model_name, model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "        results['Target'].append(target_names[i])\n",
    "        results['Model'].append(model_name)\n",
    "        results['Train Accuracy'].append(train_acc)\n",
    "        results['Train F1-Score'].append(train_f1)\n",
    "        results['CV Accuracy'].append(cv_acc_mean)\n",
    "        results['CV Accuracy Std'].append(cv_acc_std)      # сохраняем std по фолдам\n",
    "        results['CV F1-Score'].append(cv_f1_mean)\n",
    "        results['CV F1-Score Std'].append(cv_f1_std)       # сохраняем std по фолдам\n",
    "        results['Test Accuracy'].append(test_acc)\n",
    "        results['Test F1-Score'].append(test_f1)\n",
    "\n",
    "        print(f\"Target {target_names[i]} - {model_name} | \"\n",
    "              f\"Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f} | \"\n",
    "              f\"CV Acc: {cv_acc_mean:.4f} ± {cv_acc_std:.4f}, CV F1: {cv_f1_mean:.4f} ± {cv_f1_std:.4f} | \"\n",
    "              f\"Test Acc: {test_acc:.4f}, Test F1: {test_f1:.4f}\")\n",
    "\n",
    "# Create DataFrame with results\n",
    "results_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = (\n",
    "    results_df\n",
    "      .groupby('Model', as_index=False)\n",
    "      .agg(\n",
    "          cv_acc_mean_over_targets = ('CV Accuracy', 'mean'),\n",
    "          cv_acc_std_over_targets  = ('CV Accuracy', 'std'),\n",
    "          test_acc_mean_over_targets = ('Test Accuracy', 'mean'),\n",
    "          test_acc_std_over_targets  = ('Test Accuracy', 'std')\n",
    "      )\n",
    ")\n",
    "\n",
    "summary_new = summary.assign(\n",
    "    **{\n",
    "        'CV Accuracy (mean±std)':   summary['cv_acc_mean_over_targets'].map('{:.4f}'.format) +\n",
    "                                     ' ± ' + summary['cv_acc_std_over_targets'].map('{:.4f}'.format),\n",
    "        'Test Accuracy (mean±std)': summary['test_acc_mean_over_targets'].map('{:.4f}'.format) +\n",
    "                                     ' ± ' + summary['test_acc_std_over_targets'].map('{:.4f}'.format),\n",
    "    }\n",
    ")[['Model', 'CV Accuracy (mean±std)', 'Test Accuracy (mean±std)']]\n",
    "\n",
    "# (опционально) сводка по F1\n",
    "summary_f1 = (\n",
    "    results_df\n",
    "      .groupby('Model', as_index=False)\n",
    "      .agg(\n",
    "          cv_f1_mean_over_targets   = ('CV F1-Score', 'mean'),\n",
    "          cv_f1_std_over_targets    = ('CV F1-Score', 'std'),\n",
    "          test_f1_mean_over_targets = ('Test F1-Score', 'mean'),\n",
    "          test_f1_std_over_targets  = ('Test F1-Score', 'std')\n",
    "      )\n",
    ").assign(\n",
    "    **{\n",
    "        'CV F1 (mean±std)':   lambda d: d['cv_f1_mean_over_targets'].map('{:.4f}'.format) +\n",
    "                                        ' ± ' + d['cv_f1_std_over_targets'].map('{:.4f}'.format),\n",
    "        'Test F1 (mean±std)': lambda d: d['test_f1_mean_over_targets'].map('{:.4f}'.format) +\n",
    "                                        ' ± ' + d['test_f1_std_over_targets'].map('{:.4f}'.format),\n",
    "    }\n",
    ")[['Model', 'CV F1 (mean±std)', 'Test F1 (mean±std)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train F1-Score</th>\n",
       "      <th>CV Accuracy</th>\n",
       "      <th>CV Accuracy Std</th>\n",
       "      <th>CV F1-Score</th>\n",
       "      <th>CV F1-Score Std</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.749531</td>\n",
       "      <td>0.055553</td>\n",
       "      <td>0.736966</td>\n",
       "      <td>0.065007</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.634676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.707825</td>\n",
       "      <td>0.093453</td>\n",
       "      <td>0.704843</td>\n",
       "      <td>0.091767</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>0.654179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.938719</td>\n",
       "      <td>0.937346</td>\n",
       "      <td>0.757942</td>\n",
       "      <td>0.060193</td>\n",
       "      <td>0.746288</td>\n",
       "      <td>0.068899</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>0.654179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>MLP</td>\n",
       "      <td>0.760446</td>\n",
       "      <td>0.735236</td>\n",
       "      <td>0.710642</td>\n",
       "      <td>0.072118</td>\n",
       "      <td>0.681308</td>\n",
       "      <td>0.089596</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.651022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Target         Model  Train Accuracy  Train F1-Score  CV Accuracy  \\\n",
       "0  Flowers  RandomForest        1.000000        1.000000     0.749531   \n",
       "1  Flowers       XGBoost        1.000000        1.000000     0.707825   \n",
       "2  Flowers      CatBoost        0.938719        0.937346     0.757942   \n",
       "3  Flowers           MLP        0.760446        0.735236     0.710642   \n",
       "\n",
       "   CV Accuracy Std  CV F1-Score  CV F1-Score Std  Test Accuracy  Test F1-Score  \n",
       "0         0.055553     0.736966         0.065007       0.633333       0.634676  \n",
       "1         0.093453     0.704843         0.091767       0.655556       0.654179  \n",
       "2         0.060193     0.746288         0.068899       0.655556       0.654179  \n",
       "3         0.072118     0.681308         0.089596       0.677778       0.651022  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Accuracy (mean±std)</th>\n",
       "      <th>Test Accuracy (mean±std)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.7579 ± nan</td>\n",
       "      <td>0.6556 ± nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.7106 ± nan</td>\n",
       "      <td>0.6778 ± nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.7495 ± nan</td>\n",
       "      <td>0.6333 ± nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.7078 ± nan</td>\n",
       "      <td>0.6556 ± nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model CV Accuracy (mean±std) Test Accuracy (mean±std)\n",
       "0      CatBoost           0.7579 ± nan             0.6556 ± nan\n",
       "1           MLP           0.7106 ± nan             0.6778 ± nan\n",
       "2  RandomForest           0.7495 ± nan             0.6333 ± nan\n",
       "3       XGBoost           0.7078 ± nan             0.6556 ± nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV F1 (mean±std)</th>\n",
       "      <th>Test F1 (mean±std)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.7463 ± nan</td>\n",
       "      <td>0.6542 ± nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.6813 ± nan</td>\n",
       "      <td>0.6510 ± nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.7370 ± nan</td>\n",
       "      <td>0.6347 ± nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.7048 ± nan</td>\n",
       "      <td>0.6542 ± nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model CV F1 (mean±std) Test F1 (mean±std)\n",
       "0      CatBoost     0.7463 ± nan       0.6542 ± nan\n",
       "1           MLP     0.6813 ± nan       0.6510 ± nan\n",
       "2  RandomForest     0.7370 ± nan       0.6347 ± nan\n",
       "3       XGBoost     0.7048 ± nan       0.6542 ± nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results_df.head())\n",
    "display(summary_new)\n",
    "display(summary_f1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
