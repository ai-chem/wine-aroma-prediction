{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine aroma prediction using CNNs\n",
    "Here will be used CNN to predict wine aroma from the previously obtained wine composition matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.cuda.amp import autocast\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import ( \n",
    "                        average_precision_score, \n",
    "                        precision_recall_fscore_support, \n",
    "                        multilabel_confusion_matrix\n",
    ")\n",
    "import torchvision as tv\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast\n",
    "import seaborn as sns\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Working with data\n",
    "At this stage, loads the previously prepared data, and process the data for further neural networking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "X_array =  np.load('X_array.npy')\n",
    "Y_array =  np.load('Y_array.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separation of data into training, validation and test data in the ratio of 70:20:10\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_array, Y_array, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion to a tensor\n",
    "X_train = torch.tensor(X_train)\n",
    "y_train = torch.tensor(y_train)\n",
    "X_val = torch.tensor(X_val)\n",
    "y_val = torch.tensor(y_val)\n",
    "X_test = torch.tensor(X_test)\n",
    "y_test = torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323\n",
      "323\n",
      "81\n",
      "81\n",
      "45\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(X_val))\n",
    "print(len(y_val))\n",
    "print(len(X_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_amp = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom dataset\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = CustomDataset(X_train, y_train)\n",
    "dataset_val = CustomDataset(X_val, y_val)\n",
    "dataset_test = CustomDataset(X_test, y_test)\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=32, shuffle=False)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CNN architecture\n",
    "At this step it designs the architecture of the neural network, in this file the optimal architecture is specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc1): Linear(in_features=35200, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # Define convolution layers with batch normalization\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Pulling\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 11 * 25, 512)  \n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        \n",
    "        # Dropout to prevent overtraining\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.leaky_relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.leaky_relu(self.bn2(self.conv2(x))))\n",
    " \n",
    "        # Straightening before feeding to the full-link layer\n",
    "        x = x.view(-1, 128 * 11 * 25)  # Flatten\n",
    "        \n",
    "        # Fully connected layers with activation and dropout\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = self.dropout(x)  # Dropout after the first full-link layer\n",
    "        \n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Creating an instance of a neural network\n",
    "net = ConvNet()\n",
    "# Print the architecture of the neural network\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Neural network training\n",
    "Set the training parameters and train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-4\n",
    "n_splits = 5\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Herbs and spices','Tobacco/Smoke','Wood','Berries','Citrus',\n",
    "                'Fruits','Nuts','Coffee','Chocolate/Cacao','Flowers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn():\n",
    "    return ConvNet().to(device)\n",
    "\n",
    "def train_model(model, dl_train, epochs=epochs):\n",
    "    model.train()\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    for _ in range(epochs):\n",
    "        for x, y in dl_train:\n",
    "            x = x.to(device).float()\n",
    "            y = y.to(device).float()\n",
    "            if x.dim() == 3:  # (B, H, W) -> (B, 1, H, W)\n",
    "                x = x.unsqueeze(1)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits = model(x)\n",
    "            loss = loss_fn(logits, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def per_class_ap(model, dl):\n",
    "    model.eval()\n",
    "    Ys, Ps = [], []\n",
    "    for x, y in dl:\n",
    "        x = x.to(device).float()\n",
    "        y = y.to(device).float()\n",
    "        if x.dim() == 3: x = x.unsqueeze(1)\n",
    "        logits = model(x)\n",
    "        Ys.append(y.cpu().numpy())\n",
    "        Ps.append(torch.sigmoid(logits).cpu().numpy())\n",
    "    Y = np.concatenate(Ys, axis=0)  # (N, C)\n",
    "    P = np.concatenate(Ps, axis=0)  # (N, C)\n",
    "\n",
    "    C = Y.shape[1]\n",
    "    ap = np.full(C, np.nan, dtype=float)\n",
    "    support = Y.sum(axis=0)\n",
    "    for j in range(C):\n",
    "        ap[j] = average_precision_score(Y[:, j], P[:, j]) if support[j] > 0 else np.nan\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def per_sample_accuracy(model, loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    accs = []\n",
    "    for x, y in loader:\n",
    "        x = x.to(device).float()\n",
    "        if x.dim() == 3:  # (B,H,W) -> (B,1,H,W)\n",
    "            x = x.unsqueeze(1)\n",
    "        y = y.to(device).float()\n",
    "\n",
    "        logits = model(x)                         # (B, C)\n",
    "        probs  = torch.sigmoid(logits)\n",
    "        preds  = (probs > threshold).float()\n",
    "        acc_b  = (preds == y).float().mean(dim=1) # (B,)\n",
    "        accs.append(acc_b.cpu().numpy())\n",
    "    return np.concatenate(accs, axis=0)\n",
    "\n",
    "def bootstrap_mean_std(values, n_boot=2000, seed=42):\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    values = np.asarray(values, dtype=float)\n",
    "    n = len(values)\n",
    "    boot_means = [values[rng.integers(0, n, size=n)].mean() for _ in range(n_boot)]\n",
    "    return float(values.mean()), float(np.std(boot_means, ddof=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = CustomDataset(X_train, y_train)\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "idx_all = np.arange(len(X_train))\n",
    "\n",
    "ap_per_fold = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Fold 1/5 ====\n",
      "Per-class PR-AUC (val): [0.778 0.151 0.2   0.741 0.409 0.754 0.284 0.31  0.333 0.706]\n",
      "\n",
      "==== Fold 2/5 ====\n",
      "Per-class PR-AUC (val): [0.799 0.144 0.155 0.753 0.402 0.825 0.119 0.104 0.184 0.478]\n",
      "\n",
      "==== Fold 3/5 ====\n",
      "Per-class PR-AUC (val): [0.728 0.134 0.245 0.564 0.38  0.837 0.112 0.053 0.185 0.368]\n",
      "\n",
      "==== Fold 4/5 ====\n",
      "Per-class PR-AUC (val): [0.669 0.066 0.149 0.737 0.431 0.744 0.05  0.036 0.119 0.401]\n",
      "\n",
      "==== Fold 5/5 ====\n",
      "Per-class PR-AUC (val): [0.707 0.121 0.324 0.688 0.393 0.703 0.057 0.133 0.119 0.544]\n",
      "\n",
      "=== Per-class PR-AUC (CV & Test) ===\n",
      "     Aroma class  CV PR-AUC (mean)  CV PR-AUC (std)  Test PR-AUC\n",
      "          Fruits             0.773            0.057        0.919\n",
      "Herbs and spices             0.736            0.053        0.706\n",
      "         Berries             0.696            0.078        0.709\n",
      "         Flowers             0.499            0.134        0.596\n",
      "          Citrus             0.403            0.019        0.363\n",
      "            Wood             0.215            0.072        0.485\n",
      " Chocolate/Cacao             0.188            0.087        0.202\n",
      "          Coffee             0.127            0.109        0.617\n",
      "            Nuts             0.124            0.095        0.106\n",
      "   Tobacco/Smoke             0.123            0.034        0.112\n"
     ]
    }
   ],
   "source": [
    "for fold, (tr_idx, va_idx) in enumerate(kf.split(idx_all), 1):\n",
    "    print(f\"\\n==== Fold {fold}/{n_splits} ====\")\n",
    "    dl_tr = DataLoader(Subset(full_train, tr_idx), batch_size=batch_size, shuffle=True)\n",
    "    dl_va = DataLoader(Subset(full_train, va_idx), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = build_cnn()\n",
    "    model = train_model(model, dl_tr, epochs=epochs)\n",
    "    ap_fold = per_class_ap(model, dl_va)\n",
    "    ap_per_fold.append(ap_fold)\n",
    "    print(\"Per-class PR-AUC (val):\", np.round(ap_fold, 3))\n",
    "\n",
    "ap_mat = np.vstack(ap_per_fold)            # shape: (K, C)\n",
    "cv_mean = np.nanmean(ap_mat, axis=0)       # (C,)\n",
    "cv_std  = np.nanstd(ap_mat,  axis=0, ddof=1)\n",
    "\n",
    "final_ds_train = CustomDataset(X_train, y_train)\n",
    "final_dl_train = DataLoader(final_ds_train, batch_size=batch_size, shuffle=True)\n",
    "test_ds = CustomDataset(X_test, y_test)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "final_model = build_cnn()\n",
    "final_model = train_model(final_model, final_dl_train, epochs=epochs)\n",
    "test_ap = per_class_ap(final_model, test_dl)  # (C,)\n",
    "\n",
    "df_pr_auc = pd.DataFrame({\n",
    "    \"Aroma class\":        class_names,\n",
    "    \"CV PR-AUC (mean)\":   np.round(cv_mean, 3),\n",
    "    \"CV PR-AUC (std)\":    np.round(cv_std, 3),\n",
    "    \"Test PR-AUC\":        np.round(test_ap, 3)\n",
    "}).sort_values(by=\"CV PR-AUC (mean)\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"\\n=== Per-class PR-AUC (CV & Test) ===\")\n",
    "print(df_pr_auc.to_string(index=False))\n",
    "\n",
    "# df_pr_auc.to_csv(\"per_class_prauc_cv_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7978 ± 0.0187\n"
     ]
    }
   ],
   "source": [
    "test_acc_per_sample = per_sample_accuracy(final_model, test_dl, threshold=0.5)\n",
    "test_acc_mean, test_acc_std = bootstrap_mean_std(test_acc_per_sample, n_boot=2000, seed=42)\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc_mean:.4f} ± {test_acc_std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PR-AUC Bars — Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_ap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 57\u001b[0m\n\u001b[0;32m     54\u001b[0m         plt\u001b[38;5;241m.\u001b[39msavefig(savepath, dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m)\n\u001b[0;32m     55\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 57\u001b[0m plot_pr_auc_test(\u001b[43mtest_ap\u001b[49m, class_names, y_test, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, show_lift\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_ap' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_pr_auc_test(ap_values, class_names, y_test_tensor, savepath=None, show_lift=True, top_k=None):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    ap_values = np.asarray(ap_values, dtype=float)\n",
    "    if hasattr(y_test_tensor, \"cpu\"):\n",
    "        Yt = y_test_tensor.cpu().numpy()\n",
    "    else:\n",
    "        Yt = np.asarray(y_test_tensor)\n",
    "\n",
    "    # Prevalence \n",
    "    prev = np.nanmean(Yt, axis=0).astype(float)\n",
    "\n",
    "    ap_safe = np.copy(ap_values)\n",
    "    ap_sort_key = np.where(np.isnan(ap_safe), -1.0, ap_safe)\n",
    "    order = np.argsort(-ap_sort_key)\n",
    "\n",
    "    ap_sorted   = ap_values[order]\n",
    "    prev_sorted = prev[order]\n",
    "    names_sorted = [class_names[i] for i in order]\n",
    "\n",
    "    if top_k is not None:\n",
    "        k = int(min(top_k, len(ap_sorted)))\n",
    "        ap_sorted   = ap_sorted[:k]\n",
    "        prev_sorted = prev_sorted[:k]\n",
    "        names_sorted = names_sorted[:k]\n",
    "\n",
    "    y_pos = np.arange(len(ap_sorted))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    bars = ax.barh(\n",
    "        y_pos,\n",
    "        np.nan_to_num(ap_sorted, nan=0.0),\n",
    "        color=\"#a78bfa\", edgecolor=\"#6d28d9\", lw=1.2\n",
    "    )\n",
    "    ax.set_xlim(0, 1.17)\n",
    "    ax.set_xlabel(\"PR-AUC (AP) for Test Set\", fontsize=10)\n",
    "    ax.set_ylabel(\"Class\")\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(names_sorted, fontsize=12)\n",
    "    ax.grid(axis=\"x\", linestyle=\":\", alpha=0.6)\n",
    "    ax.set_title(\"PR-AUC by Class (Top {})\".format(len(ap_sorted)), fontsize=14, pad=10)\n",
    "\n",
    "    for bar, apv, pv in zip(bars, ap_sorted, prev_sorted):\n",
    "        y = bar.get_y() + bar.get_height() / 2\n",
    "        x_text = min((0.0 if np.isnan(apv) else apv) + 0.01, 0.98)\n",
    "        label = \"n/a\" if np.isnan(apv) else f\"{apv:.3f}\"\n",
    "        if show_lift:\n",
    "            label = f\"{label}  (prev {pv:.3f})\"\n",
    "        ax.text(x_text, y, label, va=\"center\", fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if savepath:\n",
    "        plt.savefig(savepath, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "plot_pr_auc_test(test_ap, class_names, y_test, top_k=10, show_lift=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] cnn_weights.pt\n"
     ]
    }
   ],
   "source": [
    "# torch.save(model.state_dict(), \"cnn_weights.pt\")\n",
    "# print(\"[saved] cnn_weights.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
